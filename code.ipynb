{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and detected!\n",
      "GPU details: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available and detected!\")\n",
    "    print(\"GPU details:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "             Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
      "0  2024-01-01 00:00:00          NaN        2.58      3.16    11.86   \n",
      "1  2024-01-01 01:00:00        55.60        2.55      3.35    11.97   \n",
      "2  2024-01-01 02:00:00        60.74        1.20      3.20    12.06   \n",
      "3  2024-01-01 03:00:00        66.15        2.67      3.56    12.95   \n",
      "4  2024-01-01 04:00:00        58.16         NaN      4.10    11.25   \n",
      "\n",
      "   Operating_Time  Humidity  Noise_Level  Energy_Consumption   Pump_Type  \\\n",
      "0            0.56     67.93        65.62                0.01      Piston   \n",
      "1            2.04     47.59        70.46                0.01  Centrifuge   \n",
      "2            3.34     56.45        63.46                0.01      Piston   \n",
      "3            4.71     43.62        69.28                0.01  Centrifuge   \n",
      "4            5.90     39.67        67.18                0.01      Piston   \n",
      "\n",
      "  Location  State  \n",
      "0   Zone A      0  \n",
      "1   Zone A      0  \n",
      "2   Zone A      0  \n",
      "3   Zone C      0  \n",
      "4   Zone B      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"maintenance_predictive.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Aperçu des données :\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations sur les colonnes :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Timestamp           5000 non-null   object \n",
      " 1   Temperature         4750 non-null   float64\n",
      " 2   Vibrations          4750 non-null   float64\n",
      " 3   Pressure            4750 non-null   float64\n",
      " 4   Current             4750 non-null   float64\n",
      " 5   Operating_Time      5000 non-null   float64\n",
      " 6   Humidity            4750 non-null   float64\n",
      " 7   Noise_Level         4750 non-null   float64\n",
      " 8   Energy_Consumption  4750 non-null   float64\n",
      " 9   Pump_Type           5000 non-null   object \n",
      " 10  Location            5000 non-null   object \n",
      " 11  State               5000 non-null   int64  \n",
      "dtypes: float64(8), int64(1), object(3)\n",
      "memory usage: 468.9+ KB\n",
      "None\n",
      "\n",
      "Valeurs manquantes par colonne :\n",
      "Timestamp               0\n",
      "Temperature           250\n",
      "Vibrations            250\n",
      "Pressure              250\n",
      "Current               250\n",
      "Operating_Time          0\n",
      "Humidity              250\n",
      "Noise_Level           250\n",
      "Energy_Consumption    250\n",
      "Pump_Type               0\n",
      "Location                0\n",
      "State                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Informations sur les colonnes :\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nValeurs manquantes par colonne :\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiques de base pour les paramètres opérationnels et mesures des capteurs :\n",
      "Moyenne :\n",
      "Temperature             57.254011\n",
      "Vibrations               3.441402\n",
      "Pressure                 3.634705\n",
      "Current                 12.343617\n",
      "Operating_Time        2479.450176\n",
      "Humidity                50.957598\n",
      "Noise_Level             72.306211\n",
      "Energy_Consumption       0.011158\n",
      "State                    0.296800\n",
      "dtype: float64\n",
      "\n",
      "Médiane :\n",
      "Temperature             55.855\n",
      "Vibrations               3.040\n",
      "Pressure                 3.530\n",
      "Current                 12.070\n",
      "Operating_Time        2483.700\n",
      "Humidity                50.630\n",
      "Noise_Level             70.670\n",
      "Energy_Consumption       0.010\n",
      "State                    0.000\n",
      "dtype: float64\n",
      "\n",
      "Écart-type :\n",
      "Temperature              9.053411\n",
      "Vibrations               2.288461\n",
      "Pressure                 0.762451\n",
      "Current                  1.733788\n",
      "Operating_Time        1428.333659\n",
      "Humidity                10.669382\n",
      "Noise_Level              8.567884\n",
      "Energy_Consumption       0.003857\n",
      "State                    0.775648\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistiques de base pour les paramètres opérationnels et mesures des capteurs :\")\n",
    "print(\"Moyenne :\")\n",
    "print(data.mean(numeric_only=True))\n",
    "\n",
    "print(\"\\nMédiane :\")\n",
    "print(data.median(numeric_only=True))\n",
    "\n",
    "print(\"\\nÉcart-type :\")\n",
    "print(data.std(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes catégoriques encodées avec Label Encoding :\n",
      "             Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
      "0  2024-01-01 00:00:00          NaN        2.58      3.16    11.86   \n",
      "1  2024-01-01 01:00:00        55.60        2.55      3.35    11.97   \n",
      "2  2024-01-01 02:00:00        60.74        1.20      3.20    12.06   \n",
      "3  2024-01-01 03:00:00        66.15        2.67      3.56    12.95   \n",
      "4  2024-01-01 04:00:00        58.16         NaN      4.10    11.25   \n",
      "5  2024-01-01 05:00:00        58.66        1.73      3.11    11.15   \n",
      "6  2024-01-01 06:00:00        67.90        4.05       NaN    13.24   \n",
      "7  2024-01-01 07:00:00          NaN        3.49      3.11    11.54   \n",
      "8  2024-01-01 08:00:00        56.98        2.27      3.08    10.74   \n",
      "9  2024-01-01 09:00:00        61.25        2.86      3.91    11.51   \n",
      "\n",
      "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
      "0            0.56     67.93        65.62                0.01          2   \n",
      "1            2.04     47.59        70.46                0.01          0   \n",
      "2            3.34     56.45        63.46                0.01          2   \n",
      "3            4.71     43.62        69.28                0.01          0   \n",
      "4            5.90     39.67        67.18                0.01          2   \n",
      "5            6.59     48.05        63.89                0.01          0   \n",
      "6            7.12     36.37        73.95                0.01          1   \n",
      "7            8.49     40.62        74.23                0.01          0   \n",
      "8            9.38     55.91        65.15                0.01          1   \n",
      "9           10.15     44.86        68.92                0.01          0   \n",
      "\n",
      "   Location  State  \n",
      "0         0      0  \n",
      "1         0      0  \n",
      "2         0      0  \n",
      "3         2      0  \n",
      "4         1      0  \n",
      "5         0      0  \n",
      "6         0      0  \n",
      "7         1      0  \n",
      "8         1      0  \n",
      "9         2      0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "categorical_columns = categorical_columns.drop('Timestamp', errors='ignore')\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "print(\"Colonnes catégoriques encodées avec Label Encoding :\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp               0\n",
      "Temperature           250\n",
      "Vibrations            250\n",
      "Pressure              250\n",
      "Current               250\n",
      "Operating_Time          0\n",
      "Humidity              250\n",
      "Noise_Level           250\n",
      "Energy_Consumption    250\n",
      "Pump_Type               0\n",
      "Location                0\n",
      "State                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données après suppression des valeurs manquantes :\n",
      "Timestamp             0\n",
      "Temperature           0\n",
      "Vibrations            0\n",
      "Pressure              0\n",
      "Current               0\n",
      "Operating_Time        0\n",
      "Humidity              0\n",
      "Noise_Level           0\n",
      "Energy_Consumption    0\n",
      "Pump_Type             0\n",
      "Location              0\n",
      "State                 0\n",
      "dtype: int64\n",
      "             Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
      "1  2024-01-01 01:00:00        55.60        2.55      3.35    11.97   \n",
      "2  2024-01-01 02:00:00        60.74        1.20      3.20    12.06   \n",
      "3  2024-01-01 03:00:00        66.15        2.67      3.56    12.95   \n",
      "5  2024-01-01 05:00:00        58.66        1.73      3.11    11.15   \n",
      "8  2024-01-01 08:00:00        56.98        2.27      3.08    10.74   \n",
      "\n",
      "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
      "1            2.04     47.59        70.46                0.01          0   \n",
      "2            3.34     56.45        63.46                0.01          2   \n",
      "3            4.71     43.62        69.28                0.01          0   \n",
      "5            6.59     48.05        63.89                0.01          0   \n",
      "8            9.38     55.91        65.15                0.01          1   \n",
      "\n",
      "   Location  State  \n",
      "1         0      0  \n",
      "2         0      0  \n",
      "3         2      0  \n",
      "5         0      0  \n",
      "8         1      0  \n"
     ]
    }
   ],
   "source": [
    "data_cleaned = data.dropna()\n",
    "print(\"Données après suppression des valeurs manquantes :\")\n",
    "print(data_cleaned.isnull().sum())\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données triées par Timestamp :\n",
      "            Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
      "1 2024-01-01 01:00:00        55.60        2.55      3.35    11.97   \n",
      "2 2024-01-01 02:00:00        60.74        1.20      3.20    12.06   \n",
      "3 2024-01-01 03:00:00        66.15        2.67      3.56    12.95   \n",
      "5 2024-01-01 05:00:00        58.66        1.73      3.11    11.15   \n",
      "8 2024-01-01 08:00:00        56.98        2.27      3.08    10.74   \n",
      "\n",
      "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
      "1            2.04     47.59        70.46                0.01          0   \n",
      "2            3.34     56.45        63.46                0.01          2   \n",
      "3            4.71     43.62        69.28                0.01          0   \n",
      "5            6.59     48.05        63.89                0.01          0   \n",
      "8            9.38     55.91        65.15                0.01          1   \n",
      "\n",
      "   Location  State  \n",
      "1         0      0  \n",
      "2         0      0  \n",
      "3         2      0  \n",
      "5         0      0  \n",
      "8         1      0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo Gaming\\AppData\\Local\\Temp\\ipykernel_16760\\2854967968.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Timestamp'] = pd.to_datetime(data_cleaned['Timestamp'])\n"
     ]
    }
   ],
   "source": [
    "# Convertir la colonne Timestamp en objet datetime\n",
    "data_cleaned['Timestamp'] = pd.to_datetime(data_cleaned['Timestamp'])\n",
    "\n",
    "data_cleaned = data_cleaned.sort_values(by='Timestamp')\n",
    "\n",
    "print(\"Données triées par Timestamp :\")\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiques de base des colonnes numériques :\n",
      "           Current  Energy_Consumption     Humidity  Noise_Level  \\\n",
      "count  3514.000000         3514.000000  3514.000000  3514.000000   \n",
      "mean     12.330953            0.011124    51.073210    72.255669   \n",
      "std       1.714884            0.003775    10.672379     8.487988   \n",
      "min       8.360000            0.010000    15.050000    47.670000   \n",
      "25%      11.390000            0.010000    43.582500    66.940000   \n",
      "50%      12.060000            0.010000    50.825000    70.680000   \n",
      "75%      12.830000            0.010000    58.017500    74.860000   \n",
      "max      19.990000            0.030000    86.920000    99.950000   \n",
      "\n",
      "       Operating_Time     Pressure  Temperature   Vibrations  \n",
      "count     3514.000000  3514.000000  3514.000000  3514.000000  \n",
      "mean      2494.091198     3.632629    57.250518     3.433717  \n",
      "std       1429.090380     0.765464     8.982524     2.262055  \n",
      "min          2.040000     1.810000    35.610000    -0.920000  \n",
      "25%       1251.172500     3.190000    51.525000     2.350000  \n",
      "50%       2499.265000     3.530000    55.885000     3.035000  \n",
      "75%       3758.875000     3.900000    61.017500     3.800000  \n",
      "max       4955.710000     7.000000    89.970000    14.880000  \n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = ['Timestamp','Pump_Type', 'Location', 'State']\n",
    "numeric_columns = data_cleaned.select_dtypes(include=['float64', 'int64']).columns.difference(columns_to_exclude)\n",
    "\n",
    "print(\"Statistiques de base des colonnes numériques :\")\n",
    "print(data_cleaned[numeric_columns].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données normalisées :\n",
      "            Timestamp  Temperature  Vibrations  Pressure   Current  \\\n",
      "1 2024-01-01 01:00:00     0.367734    0.219620  0.296724  0.310404   \n",
      "2 2024-01-01 02:00:00     0.462288    0.134177  0.267823  0.318143   \n",
      "3 2024-01-01 03:00:00     0.561810    0.227215  0.337187  0.394669   \n",
      "5 2024-01-01 05:00:00     0.424025    0.167722  0.250482  0.239897   \n",
      "8 2024-01-01 08:00:00     0.393120    0.201899  0.244701  0.204643   \n",
      "\n",
      "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
      "1        0.000000  0.452762     0.435922                 0.0        0.0   \n",
      "2        0.000262  0.576040     0.302028                 0.0        1.0   \n",
      "3        0.000539  0.397523     0.413351                 0.0        0.0   \n",
      "5        0.000919  0.459162     0.310252                 0.0        0.0   \n",
      "8        0.001482  0.568527     0.334353                 0.0        0.5   \n",
      "\n",
      "   Location  State  \n",
      "1       0.0    0.0  \n",
      "2       0.0    0.0  \n",
      "3       1.0    0.0  \n",
      "5       0.0    0.0  \n",
      "8       0.5    0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sélectionner uniquement les colonnes numériques\n",
    "numeric_columns = data_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Appliquer la normalisation (Min-Max Scaling) uniquement aux colonnes numériques\n",
    "scaler = MinMaxScaler()\n",
    "data_cleaned[numeric_columns] = scaler.fit_transform(data_cleaned[numeric_columns])\n",
    "\n",
    "print(\"Données normalisées :\")\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecteur X (features) :\n",
      "    Current  Energy_Consumption  Humidity  Location  Noise_Level  \\\n",
      "1  0.310404                 0.0  0.452762       0.0     0.435922   \n",
      "2  0.318143                 0.0  0.576040       0.0     0.302028   \n",
      "3  0.394669                 0.0  0.397523       1.0     0.413351   \n",
      "5  0.239897                 0.0  0.459162       0.0     0.310252   \n",
      "8  0.204643                 0.0  0.568527       0.5     0.334353   \n",
      "\n",
      "   Operating_Time  Pressure  Pump_Type  Temperature           Timestamp  \\\n",
      "1        0.000000  0.296724        0.0     0.367734 2024-01-01 01:00:00   \n",
      "2        0.000262  0.267823        1.0     0.462288 2024-01-01 02:00:00   \n",
      "3        0.000539  0.337187        0.0     0.561810 2024-01-01 03:00:00   \n",
      "5        0.000919  0.250482        0.0     0.424025 2024-01-01 05:00:00   \n",
      "8        0.001482  0.244701        0.5     0.393120 2024-01-01 08:00:00   \n",
      "\n",
      "   Vibrations  \n",
      "1    0.219620  \n",
      "2    0.134177  \n",
      "3    0.227215  \n",
      "5    0.167722  \n",
      "8    0.201899  \n",
      "\n",
      "Vecteur Y (target) :\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "5    0.0\n",
      "8    0.0\n",
      "Name: State, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3514, 11), (3514,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir la colonne target (Y) et les colonnes features (X)\n",
    "target_column = 'State'  \n",
    "feature_columns = data_cleaned.columns.difference([target_column]) \n",
    "\n",
    "\n",
    "X = data_cleaned[feature_columns]\n",
    "Y = data_cleaned[target_column]\n",
    "\n",
    "print(\"Vecteur X (features) :\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nVecteur Y (target) :\")\n",
    "print(Y.head())\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de X_sequences : (3504, 10, 11)\n",
      "Forme de Y_sequences : (3504,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Réinitialiser les indices de X et Y pour garantir des indices consécutifs\n",
    "X = X.reset_index(drop=True)\n",
    "Y = Y.reset_index(drop=True)\n",
    "\n",
    "# Définir la fenêtre de temps\n",
    "time_steps = 10\n",
    "\n",
    "# Créer les séquences temporelles pour X et Y\n",
    "def create_sequences(data, target, time_steps):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        # Séquence de features (X)\n",
    "        X.append(data.iloc[i:i + time_steps].values)  # Utiliser .iloc pour un accès basé sur la position\n",
    "        # Valeur cible (Y) correspondant au pas de temps suivant\n",
    "        Y.append(target.iloc[i + time_steps])  # Utiliser .iloc pour un accès basé sur la position\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Créer les séquences\n",
    "X_sequences, Y_sequences = create_sequences(X, Y, time_steps)\n",
    "\n",
    "# Afficher les formes des données préparées\n",
    "print(\"Forme de X_sequences :\", X_sequences.shape)  # (nombre de séquences, time_steps, nombre de features)\n",
    "print(\"Forme de Y_sequences :\", Y_sequences.shape)  # (nombre de séquences,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de X_train : (2452, 10, 11)\n",
      "Forme de Y_train : (2452,)\n",
      "Forme de X_test : (1052, 10, 11)\n",
      "Forme de Y_test : (1052,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement (70%) et de test (30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_sequences, Y_sequences, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "print(\"Forme de X_train :\", X_train.shape)\n",
    "print(\"Forme de Y_train :\", Y_train.shape)\n",
    "print(\"Forme de X_test :\", X_test.shape)\n",
    "print(\"Forme de Y_test :\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque [1/20], Perte : 0.2058\n",
      "Époque [2/20], Perte : 0.3483\n",
      "Époque [3/20], Perte : 0.0620\n",
      "Époque [4/20], Perte : 0.3660\n",
      "Époque [5/20], Perte : 0.0502\n",
      "Époque [6/20], Perte : 0.2042\n",
      "Époque [7/20], Perte : 0.3504\n",
      "Époque [8/20], Perte : 0.5210\n",
      "Époque [9/20], Perte : 0.7431\n",
      "Époque [10/20], Perte : 0.3664\n",
      "Époque [11/20], Perte : 0.2044\n",
      "Époque [12/20], Perte : 0.3349\n",
      "Époque [13/20], Perte : 0.1991\n",
      "Époque [14/20], Perte : 0.0622\n",
      "Époque [15/20], Perte : 0.0355\n",
      "Époque [16/20], Perte : 0.2038\n",
      "Époque [17/20], Perte : 0.3423\n",
      "Époque [18/20], Perte : 0.1966\n",
      "Époque [19/20], Perte : 0.1979\n",
      "Époque [20/20], Perte : 0.4909\n",
      "Précision sur l'ensemble de test : 0.96\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vérifier et convertir les colonnes non numériques\n",
    "X = X.select_dtypes(include=['float64', 'int64'])  # Garder uniquement les colonnes numériques\n",
    "\n",
    "# Convertir les données en tenseurs PyTorch\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y.values, dtype=torch.long)\n",
    "\n",
    "# Reformater X_tensor pour inclure une dimension temporelle\n",
    "time_steps = 10\n",
    "num_samples = X_tensor.shape[0] - time_steps\n",
    "\n",
    "X_sequences = torch.stack([X_tensor[i:i + time_steps] for i in range(num_samples)])\n",
    "Y_sequences = Y_tensor[time_steps:]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_sequences, Y_sequences, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "# Créer des DataLoaders pour l'entraînement et le test\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Définir le modèle LSTM\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out\n",
    "\n",
    "# Paramètres du modèle\n",
    "input_size = X_train.shape[2]  # Nombre de features\n",
    "hidden_size = 64  # Nombre de neurones dans la couche LSTM\n",
    "num_classes = len(Y.unique())  # Nombre de classes cibles\n",
    "\n",
    "# Initialiser le modèle, la fonction de perte et l'optimiseur\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        \n",
    "        # Backward pass et optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Époque [{epoch+1}/{num_epochs}], Perte : {loss.item():.4f}\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, Y_batch in test_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += Y_batch.size(0)\n",
    "        correct += (predicted == Y_batch).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Précision sur l'ensemble de test : {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Using cached wandb-0.19.8-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting eval-type-backport (from wandb)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (5.9.5)\n",
      "Collecting pydantic<3,>=2.6 (from wandb)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.23.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.5-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6->wandb)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=2.6->wandb)\n",
      "  Downloading pydantic_core-2.27.2-cp39-cp39-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n",
      "Using cached wandb-0.19.8-py3-none-win_amd64.whl (20.2 MB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 524.3 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 524.3 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 472.8 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 472.8 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 472.8 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 1.0/2.0 MB 474.9 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/2.0 MB 474.9 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/2.0 MB 474.9 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 486.4 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 486.4 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.6/2.0 MB 493.5 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 493.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 503.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 517.8 kB/s eta 0:00:00\n",
      "Using cached sentry_sdk-2.23.1-py2.py3-none-any.whl (336 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading setproctitle-1.3.5-cp39-cp39-win_amd64.whl (12 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, pydantic-core, eval-type-backport, docker-pycreds, annotated-types, pydantic, wandb\n",
      "Successfully installed annotated-types-0.7.0 docker-pycreds-0.4.0 eval-type-backport-0.2.2 pydantic-2.10.6 pydantic-core-2.27.2 sentry-sdk-2.23.1 setproctitle-1.3.5 wandb-0.19.8\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: mouniaabdelmoumni12 (mouniaabdelmoumni12-uuum) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.8s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo Gaming\\TP2\\wandb\\run-20250321_113850-e5uj291i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification/runs/e5uj291i' target=\"_blank\">LSTM-Training</a></strong> to <a href='https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification' target=\"_blank\">https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification/runs/e5uj291i' target=\"_blank\">https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification/runs/e5uj291i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque [1/20], Perte : 0.2756\n",
      "Époque [2/20], Perte : 0.2138\n",
      "Époque [3/20], Perte : 0.2124\n",
      "Époque [4/20], Perte : 0.2117\n",
      "Époque [5/20], Perte : 0.2108\n",
      "Époque [6/20], Perte : 0.2132\n",
      "Époque [7/20], Perte : 0.2112\n",
      "Époque [8/20], Perte : 0.2108\n",
      "Époque [9/20], Perte : 0.2127\n",
      "Époque [10/20], Perte : 0.2112\n",
      "Époque [11/20], Perte : 0.2103\n",
      "Époque [12/20], Perte : 0.2107\n",
      "Époque [13/20], Perte : 0.2113\n",
      "Époque [14/20], Perte : 0.2110\n",
      "Époque [15/20], Perte : 0.2107\n",
      "Époque [16/20], Perte : 0.2095\n",
      "Époque [17/20], Perte : 0.2088\n",
      "Époque [18/20], Perte : 0.2094\n",
      "Époque [19/20], Perte : 0.2077\n",
      "Époque [20/20], Perte : 0.2080\n",
      "Précision sur l'ensemble de test : 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>loss</td><td>0.20799</td></tr><tr><td>test_accuracy</td><td>0.96008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM-Training</strong> at: <a href='https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification/runs/e5uj291i' target=\"_blank\">https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification/runs/e5uj291i</a><br> View project at: <a href='https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification' target=\"_blank\">https://wandb.ai/mouniaabdelmoumni12-uuum/lstm-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_113850-e5uj291i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialiser W&B\n",
    "wandb.init(project=\"lstm-classification\", name=\"LSTM-Training\")\n",
    "\n",
    "# Vérifier et convertir les colonnes non numériques\n",
    "X = X.select_dtypes(include=['float64', 'int64'])  # Garder uniquement les colonnes numériques\n",
    "\n",
    "# Convertir les données en tenseurs PyTorch\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y.values, dtype=torch.long)\n",
    "\n",
    "# Reformater X_tensor pour inclure une dimension temporelle\n",
    "time_steps = 10\n",
    "num_samples = X_tensor.shape[0] - time_steps\n",
    "\n",
    "X_sequences = torch.stack([X_tensor[i:i + time_steps] for i in range(num_samples)])\n",
    "Y_sequences = Y_tensor[time_steps:]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_sequences, Y_sequences, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "# Créer des DataLoaders pour l'entraînement et le test\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Définir le modèle LSTM\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out\n",
    "\n",
    "# Paramètres du modèle\n",
    "input_size = X_train.shape[2]  # Nombre de features\n",
    "hidden_size = 64  # Nombre de neurones dans la couche LSTM\n",
    "num_classes = len(Y_tensor.unique())  # Nombre de classes cibles\n",
    "\n",
    "# Initialiser le modèle, la fonction de perte et l'optimiseur\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 20\n",
    "wandb.config.update({\"epochs\": num_epochs, \"batch_size\": 32, \"hidden_size\": hidden_size})  # Configurer les hyperparamètres\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        \n",
    "        # Backward pass et optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculer la perte moyenne pour l'époque\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    wandb.log({\"epoch\": epoch + 1, \"loss\": avg_loss})  # Enregistrer la perte dans W&B\n",
    "    \n",
    "    print(f\"Époque [{epoch+1}/{num_epochs}], Perte : {avg_loss:.4f}\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, Y_batch in test_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += Y_batch.size(0)\n",
    "        correct += (predicted == Y_batch).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "wandb.log({\"test_accuracy\": accuracy})  # Enregistrer la précision dans W&B\n",
    "print(f\"Précision sur l'ensemble de test : {accuracy:.2f}\")\n",
    "\n",
    "# Terminer la session W&B\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé sous lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le modèle entraîné\n",
    "torch.save(model.state_dict(), \"lstm_model.pth\")\n",
    "print(\"Modèle sauvegardé sous lstm_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-ngrok"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "streamlit 1.41.1 requires protobuf<6,>=3.20, but you have protobuf 3.19.6 which is incompatible."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask>=0.8 (from flask-ngrok)\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from flask-ngrok) (2.32.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
      "Collecting itsdangerous>=2.2 (from Flask>=0.8->flask-ngrok)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
      "Collecting blinker>=1.9 (from Flask>=0.8->flask-ngrok)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (8.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests->flask-ngrok) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests->flask-ngrok) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests->flask-ngrok) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from requests->flask-ngrok) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from click>=8.1.3->Flask>=0.8->flask-ngrok) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from importlib-metadata>=3.6->Flask>=0.8->flask-ngrok) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (2.1.3)\n",
      "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: itsdangerous, blinker, Flask, flask-ngrok\n",
      "  Attempting uninstall: blinker\n",
      "    Found existing installation: blinker 1.6.2\n",
      "    Uninstalling blinker-1.6.2:\n",
      "      Successfully uninstalled blinker-1.6.2\n",
      "Successfully installed Flask-3.1.0 blinker-1.9.0 flask-ngrok-0.0.25 itsdangerous-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo Gaming\\AppData\\Local\\Temp\\ipykernel_16760\\3891118269.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"lstm_model.pth\", map_location=device))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTMClassifier:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 10]) from checkpoint, the shape in current model is torch.Size([256, 11]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([2, 64]) from checkpoint, the shape in current model is torch.Size([3, 64]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMClassifier(input_size, hidden_size, num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlstm_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Initialize Flask\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo Gaming\\anaconda3\\envs\\deep_hedging\\lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTMClassifier:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 10]) from checkpoint, the shape in current model is torch.Size([256, 11]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([2, 64]) from checkpoint, the shape in current model is torch.Size([3, 64]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3])."
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model (same architecture as during training)\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out\n",
    "\n",
    "# Load the saved model\n",
    "input_size = 11  # Replace with the number of features used during training\n",
    "hidden_size = 64\n",
    "num_classes = 3  # Replace with the number of target classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"lstm_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Initialize Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define a route for predictions\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Get the JSON data sent by the client\n",
    "        data = request.get_json()\n",
    "        sequences = data['sequences']  # The sequences should be sent as a list\n",
    "\n",
    "        # Convert the data to a PyTorch tensor\n",
    "        sequences_tensor = torch.tensor(sequences, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Add a temporal dimension if necessary\n",
    "        if len(sequences_tensor.shape) == 2:\n",
    "            sequences_tensor = sequences_tensor.unsqueeze(0)  # (batch_size=1, seq_len, input_size)\n",
    "\n",
    "        # Perform the prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(sequences_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Return the prediction as JSON\n",
    "        return jsonify({'prediction': predicted.cpu().numpy().tolist()})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "# Run the Flask application\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_hedging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
